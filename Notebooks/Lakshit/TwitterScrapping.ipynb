{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nROwgnrL600G",
        "outputId": "7445c222-174a-450f-f3c7-b2023a20347a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dmg9fmwD9yu_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "# Provide your Bearer Token\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAKKwyAEAAAAAHWRWJIG0fcNZlFYbBSIrEzYclm0%3DQdb24tcUzU8Ys502eSnymYi9jg8EHFwmZfrPiVdfjIiwv1dTkk\"\n",
        "\n",
        "# Initialize Tweepy Client\n",
        "client = tweepy.Client(bearer_token=bearer_token)\n",
        "\n",
        "# Define query for #Costco\n",
        "query = \"#Costco -is:retweet\"\n",
        "\n",
        "# Create a list to store the data\n",
        "tweets_data = []\n",
        "\n",
        "# Track the total number of requests made\n",
        "total_requests = 0\n",
        "max_requests = 100  # Set your monthly request limit\n",
        "\n",
        "try:\n",
        "    # Fetch 5 tweets\n",
        "    if total_requests < max_requests:\n",
        "        response = client.search_recent_tweets(\n",
        "            query=query,\n",
        "            max_results=5,  # Fetch only 5 tweets\n",
        "            tweet_fields=[\"created_at\", \"author_id\", \"conversation_id\", \"public_metrics\", \"lang\"]\n",
        "        )\n",
        "        total_requests += 1  # Increment requests for the tweet search\n",
        "\n",
        "        if response.data:\n",
        "            for tweet in response.data:\n",
        "                tweet_id = tweet.id\n",
        "                conversation_id = tweet.conversation_id  # Replies are in the same conversation_id\n",
        "                author_id = tweet.author_id\n",
        "                text = tweet.text\n",
        "                created_at = tweet.created_at\n",
        "\n",
        "                # Add the original tweet to the dataset\n",
        "                tweets_data.append({\n",
        "                    \"tweet_id\": tweet_id,\n",
        "                    \"conversation_id\": conversation_id,\n",
        "                    \"author_id\": author_id,\n",
        "                    \"created_at\": created_at,\n",
        "                    \"text\": text,\n",
        "                    \"is_reply\": False,  # Mark it as the original tweet\n",
        "                })\n",
        "\n",
        "                # Fetch up to 5 replies for this tweet if under request limit\n",
        "                if total_requests < max_requests:\n",
        "                    time.sleep(1)  # Add a delay to avoid rapid-fire requests\n",
        "                    reply_query = f\"conversation_id:{conversation_id} -is:retweet\"\n",
        "                    reply_response = client.search_recent_tweets(\n",
        "                        query=reply_query,\n",
        "                        max_results=5,  # Fetch up to 5 replies per conversation\n",
        "                        tweet_fields=[\"created_at\", \"author_id\", \"conversation_id\"]\n",
        "                    )\n",
        "                    total_requests += 1  # Increment requests for each reply search\n",
        "\n",
        "                    if reply_response.data:\n",
        "                        for reply in reply_response.data:\n",
        "                            # Avoid re-adding the original tweet\n",
        "                            if reply.id == tweet_id:\n",
        "                                continue\n",
        "\n",
        "                            tweets_data.append({\n",
        "                                \"tweet_id\": reply.id,\n",
        "                                \"conversation_id\": reply.conversation_id,\n",
        "                                \"author_id\": reply.author_id,\n",
        "                                \"created_at\": reply.created_at,\n",
        "                                \"text\": reply.text,\n",
        "                                \"is_reply\": True,  # Mark it as a reply\n",
        "                            })\n",
        "\n",
        "except tweepy.TooManyRequests as e:\n",
        "    reset_time = int(e.response.headers.get(\"x-rate-limit-reset\", 0))\n",
        "    wait_time = max(0, reset_time - int(time.time()))  # Calculate wait time\n",
        "    print(f\"Rate limit hit. Sleeping for {wait_time} seconds...\")\n",
        "    time.sleep(wait_time + 1)  # Sleep until the rate limit resets\n",
        "    print(\"Resuming...\")\n",
        "\n",
        "# Save the data to a CSV file\n",
        "df = pd.DataFrame(tweets_data)\n",
        "df.to_csv(\"tweets_costco_limited.csv\", index=False)\n",
        "print(f\"Saved data to tweets_costco_limited.csv. Total requests used: {total_requests}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxwKYsjQ-g9L",
        "outputId": "93ba842f-cacd-4426-9a13-4a1161a1cbc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit hit. Sleeping for 569 seconds...\n",
            "Resuming...\n",
            "Saved data to tweets_costco_limited.csv. Total requests used: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RfVx1_HQ_Q2T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}